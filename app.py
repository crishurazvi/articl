import streamlit as st
import yt_dlp
import os
import glob
import math

# --- CONFIGURARE PAGINÄ‚ ---
st.set_page_config(page_title="AI Debate & Summary", page_icon="ğŸ§ ")
st.title("ğŸ§  Analizator Universal (Video & Text)")

# --- SELECTOR DE MOD ---
mod_lucru = st.radio("Ce vrei sÄƒ analizezi?", ["ğŸ“º Video YouTube", "ğŸ“ Text / Postare Facebook / Articol"])

# --- CONFIGURÄ‚RI GENERALE ---
st.write("ğŸ”§ **SetÄƒri:**")
CHUNK_SIZE = st.slider("MÄƒrime bucatÄƒ (caractere)", 2000, 30000, 15000, 1000)

# --- PROMPTURI INTELIGENTE ---
PROMPT_VIDEO = """
EÈ™ti un analist expert. AnalizeazÄƒ acest transcript (Partea {part}/{total}) È™i aÈ™teaptÄƒ continuarea.
La final, livreazÄƒ Ã®n ROMÃ‚NÄ‚:
1. REZUMAT EXECUTIV.
2. IDEI PRINCIPALE.
3. CONCLUZIE PRACTICÄ‚.
"""

PROMPT_DEBATE = """
EÈ™ti un moderator de dezbateri expert È™i un logician desÄƒvÃ¢rÈ™it.
AnalizeazÄƒ textul furnizat mai jos (care poate fi o postare Facebook, un articol sau o opinie) È™i realizeazÄƒ urmÄƒtoarele Ã®n limba ROMÃ‚NÄ‚:

1. ğŸ•µï¸â€â™‚ï¸ VERIFICAREA FAPTELOR (Fact-Check): ExistÄƒ afirmaÈ›ii dubioase?
2. ğŸ¥Š DEZBATERE (PRO vs CONTRA): PrezintÄƒ argumentele autorului È™i contra-argumente solide.
3. âš–ï¸ ANALIZÄ‚ LOGICÄ‚: IdentificÄƒ erori de logicÄƒ (sofisme) sau manipulare emoÈ›ionalÄƒ.
4. ğŸ“ REZUMAT IMPARÈšIAL.

IatÄƒ textul de analizat:
--------------------------------------------------
"""

# ==========================================
# LOGICA PENTRU YOUTUBE
# ==========================================
if mod_lucru == "ğŸ“º Video YouTube":
    url = st.text_input("LipeÈ™te Link-ul YouTube:")
    
    if st.button("Extrage È™i PregÄƒteÈ™te"):
        if not url:
            st.warning("Pune un link!")
        else:
            status = st.empty()
            status.info("â³ Descarc subtitrarea...")
            
            options = {
                'skip_download': True,
                'writeautomaticsub': True,
                'writesubtitles': True,
                'subtitleslangs': ['en', 'ro'], # ÃncercÄƒm È™i RO È™i EN
                'outtmpl': 'temp_stream',
                'quiet': True,
                'no_warnings': True
            }

            try:
                for f in glob.glob("temp_stream*"): 
                    try: os.remove(f)
                    except: pass

                with yt_dlp.YoutubeDL(options) as ydl:
                    ydl.download([url])

                files = glob.glob("temp_stream*.vtt")
                
                if files:
                    filename = files[0]
                    with open(filename, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                    
                    full_text_list = []
                    seen = set()
                    for line in lines:
                        line = line.strip()
                        if "-->" in line or line == "WEBVTT" or not line: continue
                        if line.startswith("<") and line.endswith(">"): continue
                        if "<" in line and ">" in line:
                            import re
                            line = re.sub(r'<[^>]+>', '', line)
                        if line in seen: continue
                        seen.add(line)
                        full_text_list.append(line)

                    whole_text = " ".join(full_text_list)
                    
                    # Logica de Ã®mpÄƒrÈ›ire (Chunking)
                    num_chunks = math.ceil(len(whole_text) / CHUNK_SIZE)
                    
                    status.success(f"âœ… Transcript extras! ({len(whole_text)} caractere)")
                    st.markdown("---")
                    
                    for i in range(num_chunks):
                        start = i * CHUNK_SIZE
                        end = start + CHUNK_SIZE
                        chunk = whole_text[start:end]
                        
                        header = PROMPT_VIDEO.format(part=i+1, total=num_chunks)
                        final_block = header + "\n" + chunk
                        
                        st.subheader(f"ğŸ”¹ Partea {i+1}")
                        st.code(final_block, language=None)
                        st.markdown("---")

                    os.remove(filename)
                else:
                    status.error("Nu am gÄƒsit subtitrÄƒri (YouTube nu le are sau link-ul e greÈ™it).")
            except Exception as e:
                status.error(f"Eroare: {str(e)}")

# ==========================================
# LOGICA PENTRU FACEBOOK / TEXT
# ==========================================
elif mod_lucru == "ğŸ“ Text / Postare Facebook / Articol":
    st.info("Pentru Facebook/È˜tiri: CopiazÄƒ textul manual È™i lipeÈ™te-l aici. Eu voi crea prompt-ul perfect pentru AI.")
    
    raw_text = st.text_area("LipeÈ™te textul aici:", height=300)
    
    if st.button("GenereazÄƒ Analiza DEBATE"):
        if not raw_text:
            st.warning("Nu ai lipit niciun text.")
        else:
            # Aici nu mai avem nevoie neapÄƒrat de chunking complex dacÄƒ textul e mic,
            # dar Ã®l pÄƒstrÄƒm pentru articole foarte lungi.
            num_chunks = math.ceil(len(raw_text) / CHUNK_SIZE)
            
            st.success(f"âœ… Text procesat! PregÄƒtit pentru dezbatere.")
            st.markdown("---")
            
            for i in range(num_chunks):
                start = i * CHUNK_SIZE
                end = start + CHUNK_SIZE
                chunk = raw_text[start:end]
                
                # DacÄƒ e o singurÄƒ bucatÄƒ, punem promptul direct
                # DacÄƒ sunt mai multe, i-am putea spune AI-ului sÄƒ aÈ™tepte, 
                # dar pentru debate e mai bine sÄƒ analizeze tot odatÄƒ dacÄƒ Ã®ncape.
                
                final_block = PROMPT_DEBATE + "\n" + chunk
                
                st.subheader(f"ğŸ”¹ AnalizÄƒ Debate (Partea {i+1})")
                st.caption("CopiazÄƒ asta Ã®n ChatGPT/Gemini:")
                st.code(final_block, language=None)
                st.markdown("---")
